# ğŸ¤– ML Model KullanÄ±m KÄ±lavuzu

## ğŸ“Š Model Ã–zeti

### **Model Tipi: REGRESSION âœ…**

- **AmaÃ§:** Form skorunu 0-100 arasÄ± sÃ¼rekli deÄŸer olarak tahmin etmek
- **Algoritmalar:** Random Forest, Gradient Boosting, Ridge
- **Performance Metrics:** MSE, MAE, RÂ² Score

---

## ğŸš€ KullanÄ±m

### **1. Temel Model EÄŸitimi**

```bash
# Belirli bir hareket iÃ§in
python train_form_model.py bicep_curls random_forest

# TÃ¼m hareketler iÃ§in
python train_form_model.py all random_forest

# Model tipleri:
# - random_forest (Ã¶nerilen)
# - gradient_boosting
# - ridge
```

---

### **2. Cross-Validation ile EÄŸitim**

```bash
# 5-fold cross-validation ile eÄŸit
python train_form_model.py bicep_curls random_forest --cv
# veya kÄ±sa: -c
python train_form_model.py bicep_curls random_forest -c
```

**Avantajlar:**
- âœ… Daha robust performance estimation
- âœ… Overfitting tespiti
- âœ… TÃ¼m veriyi kullanÄ±r

**Ã‡Ä±ktÄ±:**
```
ğŸ“Š Cross-Validation (5-fold)...
   CV MAE: 6.25 (Â±1.2)
   CV RÂ²:  0.87 (Â±0.05)

ğŸ“ˆ Test Set Results:
   Test MAE: 6.50
   Test RÂ²:  0.85
```

---

### **3. Hyperparameter Tuning ile EÄŸitim**

```bash
# RandomizedSearch ile hyperparameter tuning
python train_form_model.py bicep_curls random_forest --tune
# veya kÄ±sa: -t
python train_form_model.py bicep_curls random_forest -t
```

**Avantajlar:**
- âœ… Optimal hyperparameter'larÄ± bulur
- âœ… Cross-validation ile robust
- âœ… Overfitting riskini azaltÄ±r

**Ã‡Ä±ktÄ±:**
```
ğŸ” Hyperparameter tuning enabled (random search)...
ğŸ” Searching best hyperparameters...
âœ… Best hyperparameters:
   n_estimators: 200
   max_depth: 15
   min_samples_split: 5
   min_samples_leaf: 2
   Best CV MAE: 5.8
```

---

### **4. Kombine: CV + Tuning**

```bash
# Hem CV hem tuning
python train_form_model.py bicep_curls random_forest --cv --tune
# veya kÄ±sa
python train_form_model.py bicep_curls random_forest -c -t
```

---

## ğŸ“ˆ Performance Metrics

### **Mean Absolute Error (MAE)**
- **Birim:** Score (puan)
- **Yorumlama:** Ortalama mutlak hata
- **Hedef:** < 7 puan

**Ã–rnek:**
```
MAE = 6.5
â†’ Model tahminleri ortalama 6.5 puan hata yapÄ±yor
```

---

### **Mean Squared Error (MSE)**
- **Birim:** ScoreÂ²
- **Yorumlama:** BÃ¼yÃ¼k hatalara daha fazla aÄŸÄ±rlÄ±k verir
- **Hedef:** < 50

**Ã–rnek:**
```
MSE = 45.2
â†’ RMSE = âˆš45.2 = 6.7 puan
```

---

### **RÂ² Score (Coefficient of Determination)**
- **AralÄ±k:** 0-1 (veya negatif)
- **Yorumlama:** Variance'Ä±n ne kadarÄ±nÄ± aÃ§Ä±klÄ±yor
- **Hedef:** > 0.85

**Ã–rnek:**
```
RÂ² = 0.87
â†’ Model variance'Ä±n %87'sini aÃ§Ä±klÄ±yor
```

---

## ğŸ¯ Hyperparameter Tuning DetaylarÄ±

### **Random Forest:**

**Tuned Parameters:**
- `n_estimators`: 50-300 (aÄŸaÃ§ sayÄ±sÄ±)
- `max_depth`: 5, 10, 15, 20, None
- `min_samples_split`: 2-20
- `min_samples_leaf`: 1-10

**Default (Tuning olmadan):**
```python
n_estimators=100
max_depth=10
min_samples_split=5
min_samples_leaf=1
```

---

### **Gradient Boosting:**

**Tuned Parameters:**
- `n_estimators`: 50-200
- `max_depth`: 3, 5, 7, 10
- `learning_rate`: 0.01-0.2
- `min_samples_split`: 2-20

**Default:**
```python
n_estimators=100
max_depth=5
learning_rate=0.1
min_samples_split=2
```

---

### **Ridge:**

**Tuned Parameters:**
- `alpha`: 0.1, 0.5, 1.0, 5.0, 10.0, 50.0

**Default:**
```python
alpha=1.0
```

---

## ğŸ“Š Beklenen Performans

### **Minimum (Baseline - Ridge):**
- **MAE:** < 10 puan
- **RÂ²:** > 0.70
- **MSE:** < 100

### **Ä°yi (Random Forest - Default):**
- **MAE:** < 7 puan
- **RÂ²:** > 0.85
- **MSE:** < 50

### **MÃ¼kemmel (Random Forest - Tuned):**
- **MAE:** < 5 puan
- **RÂ²:** > 0.90
- **MSE:** < 25

---

## ğŸ”§ Python API KullanÄ±mÄ±

### **Temel EÄŸitim:**

```python
from ml_trainer import FormScorePredictor
from dataset_collector import DatasetCollector

# Dataset yÃ¼kle
collector = DatasetCollector("dataset")
samples = collector.load_dataset()

# Model eÄŸit
predictor = FormScorePredictor(model_type="random_forest")
results = predictor.train(samples, verbose=True)

# Model kaydet
predictor.save("models/form_score_predictor")
```

---

### **Hyperparameter Tuning:**

```python
# Tuning yap
best_params = predictor.tune_hyperparameters(
    samples,
    cv=5,
    method="random",  # "grid" or "random"
    n_iter=50,
    verbose=True
)

# EÄŸit (tuned hyperparameter'lar ile)
results = predictor.train(samples, verbose=True)
```

---

### **Cross-Validation ile EÄŸitim:**

```python
# CV ile eÄŸit
results = predictor.train_with_cv(
    samples,
    cv=5,
    test_size=0.2,
    verbose=True
)

# CV scores:
# - cv_mae_mean: Ortalama CV MAE
# - cv_mae_std: CV MAE standart sapmasÄ±
# - cv_r2_mean: Ortalama CV RÂ²
# - cv_r2_std: CV RÂ² standart sapmasÄ±
```

---

### **Model KullanÄ±mÄ±:**

```python
# Model yÃ¼kle
predictor = FormScorePredictor.load("models/form_score_predictor")

# Feature'larÄ± Ã§Ä±kar
features = collector.extract_features(sample)

# Form skoru tahmin et
predicted_score = predictor.predict(features)
print(f"Predicted form score: {predicted_score:.1f}%")

# Feature importance
importances = predictor.get_feature_importance(top_n=10)
for feature, importance in importances.items():
    print(f"{feature}: {importance:.4f}")
```

---

## âš™ï¸ Komut SatÄ±rÄ± SeÃ§enekleri

```bash
# Temel kullanÄ±m
python train_form_model.py [exercise] [model_type]

# SeÃ§enekler:
# --cv, -c          : Cross-validation kullan
# --tune, -t        : Hyperparameter tuning yap

# Ã–rnekler:
python train_form_model.py bicep_curls random_forest
python train_form_model.py bicep_curls random_forest --cv
python train_form_model.py bicep_curls random_forest --tune
python train_form_model.py bicep_curls random_forest --cv --tune
python train_form_model.py all gradient_boosting -c -t
```

---

## ğŸ“ Ã–rnek Ã‡Ä±ktÄ±

```
============================================================
Training random_forest model
============================================================

ğŸ“Š Dataset:
   Total samples: 150
   Features: 120
   Label range: 45.0 - 98.0

ğŸ“¦ Split:
   Train: 120 samples
   Test: 30 samples

ğŸ” Hyperparameter tuning enabled (random search)...
ğŸ” Searching best hyperparameters...
Fitting 5 folds for each of 50 candidates, totalling 250 fits
âœ… Best hyperparameters:
   n_estimators: 200
   max_depth: 15
   min_samples_split: 5
   min_samples_leaf: 2
   Best CV MAE: 5.8

ğŸš€ Training...

ğŸ“Š Cross-Validation (5-fold)...
   CV MAE: 5.85 (Â±1.1)
   CV RÂ²:  0.89 (Â±0.04)

ğŸ“ˆ Test Set Results:
   Test MSE: 38.5
   Test MAE: 6.2
   Test RÂ²:  0.87

ğŸ“ˆ Top 10 Most Important Features:
   left_elbow_range: 0.1523
   left_elbow_min: 0.1234
   right_elbow_vel_mean: 0.0987
   ...

âœ… Training complete!
```

---

## ğŸ¯ Ã–neriler

1. **Ä°lk eÄŸitim:** Temel train (tuning olmadan)
2. **Performans yetersizse:** `--tune` ile hyperparameter tuning
3. **Robust evaluation:** `--cv` ile cross-validation
4. **Production:** Tuned model + CV evaluation

---

## âš ï¸ Notlar

- **Minimum veri:** En az 20-30 sample (CV iÃ§in daha fazla Ã¶nerilir)
- **Tuning sÃ¼resi:** RandomizedSearch daha hÄ±zlÄ± (GridSearch daha uzun)
- **CV folds:** 5-fold Ã¶nerilir (3-fold daha az veri iÃ§in)

